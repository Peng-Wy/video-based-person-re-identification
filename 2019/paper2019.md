
Title|Figure| Results| Pub | Links
 --- |  --- |  ---   |---  |---  
Temporal Knowledge Propagation for Image-to-Video Person Re-identifification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/1.png)|Ilids-VID:Rank1=54.6%; MARS:Rank1=75.6% mAP=65.1%;|ICCV2019|[Paper](https://arxiv.org/pdf/1908.03885.pdf) [Code](https://github.com/guxinqian/TKP)
Co-segmentation Inspired Attention Networks for Video-based Person Re-identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/co-segementation.png) | ilids-VID: rank1=75.5%; MARS:mAP=77.2% rank1=83.7%;   DukeMTMC-video:mAP=94% rank1=94.4%; |ICCV2019| [Paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Subramaniam_Co-Segmentation_Inspired_Attention_Networks_for_Video-Based_Person_Re-Identification_ICCV_2019_paper.pdf)[Code](https://github.com/InnovArul/vidreid_cosegmentation)
Spatially and Temporally Efficient Non-local Attention Network for Video-based Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/non-local.png) |MARS:  rank1=90% mAP=82.8%; DukeMTMC-video:rank1=96.3% mAP=94.9% | BMVC2019 | [Paper](http://media.ee.ntu.edu.tw/research/STE_NVAN/BMVC19_STE_NVAN_cam.pdf)[Code](https://github.com/jackie840129/STE-NVAN)
STA: Spatial-Temporal Attention for Large-Scale Video-based Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/sta.png) | MARS:rank1=86.3% mAP=80.8%;  DukeMTMC-video: rank1=96.2% mAP=94.9%;|AAAI2019|[paper](https://arxiv.org/abs/1811.04129) 
Spatial and Temporal Mutual Promotion for Video-based Person Re-identification| ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/RRU_STIM.png) |ilids-VID:rank1=84.3% ;PRID2011: rank1=92.7% ;MARS:rank1=84.4% mAP=72.7%;|AAAI2019| [Paper](https://arxiv.org/abs/1812.10305v1)[Code](https://github.com/yolomax/rru-reid)
SCAN: Self-and-Collaborative Attention Network for Video Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/SCAN.png) | ilids-VID:rank1=88%; PRID2011:rank1=95.3%; MARS:rank1=87.2% mAP=77.2%; | TIP2019 | [Paper](https://ieeexplore.ieee.org/document/8703416)[Code](https://github.com/ruixuejianfei/SCAN)
Weakly Supervised Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/weakly.png) |WL-ilids-VID:rank1=60% mAP=56.01%; ML-PRID2011:rank1=72% mAP=70.78%; ML-MARS:rank1=66.88% mAP=55.16; WL-DukeMTMC-video:rank1=78.05% mAP=59.53%;|CVPR2019|[Paper](https://arxiv.org/abs/1904.03832v1)
Attribute-Driven Feature Disentangling and Temporal Aggregation for Video Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/attribute.png)|ilids-VID:rank1=86.3%; PRID2011:rank1=93.9%; MARS:rank1=87% mAP=78.2%; | CVPR2019 [Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Attribute-Driven_Feature_Disentangling_and_Temporal_Aggregation_for_Video_Person_Re-Identification_CVPR_2019_paper.pdf)
VRSTC: Occlusion-Free Video Person Re-Identification | ![image](https://github.com/ccq195/video-based-person-re-identification/blob/master/2019/figure/VRSTC.png) | ilids-VID:rank1=83.4%; DukeMTMC-video:rank1=95% mAP=93.5%; MARS:rank1=88.5% mAP=82.3%;